\chapter*{Висновки}
\markboth{Висновки}{Висновки}
\addcontentsline{toc}{chapter}{Висновки}

\hspace{\parindent} В цій роботі були розглянуті фундаментальні та формалізовані
принципи роботи нейронних мереж. Ми конкретизували основну проблематику 
машинного навчання та, зокрема, яка роль нейронних мереж у вирішенні цих
проблем. Ми навели визначення та теореми, що показують дві парадигми 
побудови архітектур нейронних мереж: мультишарові перцептрони (MLP) та 
мережі Колмогорова-Арнольда (KAN). Для обох парадигм ми навели теореми,
що доводять універсальність цих архітектур для апроксимації довільних 
функцій на гіперкубі $[0, 1]^m$. Ми також розглянули проблематику
вибору кількості шарів та нейронів у кожному з них, а також вибору
функції активації. Ми навели приклади використання нейронних мереж для
розв'язання задач класифікації і показали на практиці, що теорема 
Цибенко дійсно працює для складної функції. 

Нарешті, коли ми окреслили основну відмінність між MLP та KAN, ми розширили цю
ідею на конволюційні нейронні мережі (CNN) та провели експерименти на наборі
даних MNIST за допомогою нейронних мереж, що повністю складалися з шарів KAN.
Незважаючи на складнощі в процесі тренування, отримана точність у 87.8\%
точності показує перспективність використання KAN для задач комп'ютерного зору.