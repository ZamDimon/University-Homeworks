\chapter*{Анотації}
\markboth{Анотації}{Анотації}
\addcontentsline{toc}{chapter}{Анотації}

\subsubsection{Захаров Д.О. Архітектури нейронних мереж з ефективними активаціями.}

Через зростання попиту у розробці архітектур нейронних мереж, потреба в
конфіденційності їх обчислень стала першорядною. З цієї причини, галузь
доказів із нульовим знанням і повністю гомоморфного шифрування активно
досліджувалися для роботи над нейронними мережами. Однак функції активації, які
використовуються в нейронних мережах, не завжди сумісні з існуючими
арифметизаціями криптографічних примітивів. У цій статті ми аналізуємо, чи можна
оптимізувати функції активації, які використовуються в нейронних мережах, щоб
зробити їх більш «криптографічно-сумісними».

\subsubsection{Zakharov D.O. Activation-Efficient Neural Network Architectures.}

Due to the rise of neural network architectures, the need for their privacy and
privacy-preserving computations became paramount. For that reason, the
fields of zero-knowledge proofs and fully homomorphic encryption have been
actively researched to work on top of neural networks. However, the
activation functions used in neural networks are not always compatible with
the existing arithmetizations of cryptographic primitives. In this paper, we
analyze whether the activation functions used in neural networks can be
optimized for the sake of making them more ``cryptographically friendly''.
