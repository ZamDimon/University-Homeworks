@inproceedings{nns-in-cv-1,
   title={Graph Neural Networks in Computer Vision - Architectures, Datasets and Common Approaches},
   url={http://dx.doi.org/10.1109/IJCNN55064.2022.9892658},
   DOI={10.1109/ijcnn55064.2022.9892658},
   booktitle={2022 International Joint Conference on Neural Networks (IJCNN)},
   publisher={IEEE},
   author={Krzywda, Maciej and Lukasik, Szymon and Gandomi, Amir H.},
   year={2022},
   month=jul, pages={1–10} }

@misc{nns-in-cv-2,
	title={Neural World Models for Computer Vision}, 
	author={Anthony Hu},
	year={2023},
	eprint={2306.09179},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/2306.09179}, 
}


@article{not-polynomials,
	abstract = {Several researchers characterized the activation function under which multilayer feedforward networks can act as universal approximators. We show that most of all the characterizations that were reported thus far in the literature are special cases of the following general result: A standard multilayer feedforward network with a locally bounded piecewise continuous activation function can approximate any continuous function to any degree of accuracy if and only if the network's activation function is not a polynomial. We also emphasize the important role of the threshold, asserting that without it the last theorem does not hold.},
	author = {Moshe Leshno and Vladimir Ya. Lin and Allan Pinkus and Shimon Schocken},
	doi = {https://doi.org/10.1016/S0893-6080(05)80131-5},
	issn = {0893-6080},
	journal = {Neural Networks},
	keywords = {Multilayer feedforward networks, Activation functions, Role of threshold, Universal approximation capabilities, (μ) approximation},
	number = {6},
	pages = {861-867},
	title = {Multilayer feedforward networks with a nonpolynomial activation function can approximate any function},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608005801315},
	volume = {6},
	year = {1993},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0893608005801315},
	bdsk-url-2 = {https://doi.org/10.1016/S0893-6080(05)80131-5}}

@misc{nns-in-nlps-1,
	title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, 
	author={DeepSeek-AI and Daya Guo and Dejian Yang and Haowei Zhang and et al.},
	year={2025},
	eprint={2501.12948},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/2501.12948}, 
}

@misc{nns-in-nlps-2,
	title={Attention Is All You Need}, 
	author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
	year={2023},
	eprint={1706.03762},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/1706.03762}, 
}

@inproceedings{fhe-training,
	author = {Colombo, Luca and Falcetta, Alessandro and Roveri, Manuel},
	title = {Training Encrypted Neural Networks on Encrypted Data with Fully Homomorphic Encryption},
	year = {2024},
	isbn = {9798400712418},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3689945.3694802},
	doi = {10.1145/3689945.3694802},
	abstract = {Training machine and deep learning models on encrypted data is the next challenge in the field of privacy-preserving Machine and Deep Learning. The related literature in this field is very limited, since most of the solutions focus only on inference on encrypted data (leaving the training to be carried out on plain data). In this paper we introduce a multi-class and non-linear family of neural networks based on the Torus Fully Homomorphic Encryption (TFHE) scheme (named TFHE-NNs), which can be entirely trained on encrypted data. The proposed learning procedure, implementing a TFHE-compliant version of the Direct-Feedback-Alignment algorithm, is combined with a novel Cross-Validation procedure able to operate on encrypted models and encrypted accuracy. The experimental results demonstrate the feasibility of the proposed solution. The proposed models and algorithms are made available to the scientific community as a public repository.},
	booktitle = {Proceedings of the 12th Workshop on Encrypted Computing \& Applied Homomorphic Cryptography},
	pages = {64–75},
	numpages = {12},
	keywords = {deep learning, homomorphic encryption, machine learning, privacy-preserving, tfhe},
	location = {Salt Lake City, UT, USA},
	series = {WAHC '24}
}

@misc{zk-training,
	author = {Haochen Sun and Tonghe Bai and Jason Li and Hongyang Zhang},
	title = {{zkDL}: Efficient Zero-Knowledge Proofs of Deep Learning Training},
	howpublished = {Cryptology {ePrint} Archive, Paper 2023/1174},
	year = {2023},
	url = {https://eprint.iacr.org/2023/1174}
}

@misc{mobilenetv3,
	title={Searching for MobileNetV3}, 
	author={Andrew Howard and Mark Sandler and Grace Chu and Liang-Chieh Chen and Bo Chen and Mingxing Tan and Weijun Wang and Yukun Zhu and Ruoming Pang and Vijay Vasudevan and Quoc V. Le and Hartwig Adam},
	year={2019},
	eprint={1905.02244},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/1905.02244}, 
}

@misc{spartan,
      author = {Srinath Setty},
      title = {Spartan: Efficient and general-purpose {zkSNARKs} without trusted setup},
      howpublished = {Cryptology {ePrint} Archive, Paper 2019/550},
      year = {2019},
      url = {https://eprint.iacr.org/2019/550}
}

@misc{cryptonets,
	title={Crypto-Nets: Neural Networks over Encrypted Data}, 
	author={Pengtao Xie and Misha Bilenko and Tom Finley and Ran Gilad-Bachrach and Kristin Lauter and Michael Naehrig},
	year={2014},
	eprint={1412.6181},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1412.6181}, 
}

@misc{ligero,
      author = {Scott Ames and Carmit Hazay and Yuval Ishai and Muthuramakrishnan Venkitasubramaniam},
      title = {Ligero: Lightweight Sublinear Arguments Without a Trusted Setup},
      howpublished = {Cryptology {ePrint} Archive, Paper 2022/1608},
      year = {2022},
      doi = {10.1145/3133956},
      url = {https://eprint.iacr.org/2022/1608}
}


@inproceedings{gsw,
	abstract = {We describe a comparatively simple fully homomorphic encryption (FHE) scheme based on the learning with errors (LWE) problem. In previous LWE-based FHE schemes, multiplication is a complicated and expensive step involving ``relinearization''. In this work, we propose a new technique for building FHE schemes that we call the approximate eigenvector method. In our scheme, for the most part, homomorphic addition and multiplication are just matrix addition and multiplication. This makes our scheme both asymptotically faster and (we believe) easier to understand.},
	address = {Berlin, Heidelberg},
	author = {Gentry, Craig and Sahai, Amit and Waters, Brent},
	booktitle = {Advances in Cryptology -- CRYPTO 2013},
	editor = {Canetti, Ran and Garay, Juan A.},
	isbn = {978-3-642-40041-4},
	pages = {75--92},
	publisher = {Springer Berlin Heidelberg},
	title = {Homomorphic Encryption from Learning with Errors: Conceptually-Simpler, Asymptotically-Faster, Attribute-Based},
	year = {2013}}

@inproceedings{zkml,
author = {Chen, Bing-Jyue and Waiwitlikhit, Suppakit and Stoica, Ion and Kang, Daniel},
title = {ZKML: An Optimizing System for ML Inference in Zero-Knowledge Proofs},
year = {2024},
isbn = {9798400704376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627703.3650088},
doi = {10.1145/3627703.3650088},
abstract = {Machine learning (ML) is increasingly used behind closed systems and APIs to make important decisions. For example, social media uses ML-based recommendation algorithms to decide what to show users, and millions of people pay to use ChatGPT for information every day. Because ML is deployed behind these closed systems, there are increasing calls for transparency, such as releasing model weights. However, these service providers have legitimate reasons not to release this information, including for privacy and trade secrets. To bridge this gap, recent work has proposed using zero-knowledge proofs (specifically a form called ZK-SNARKs) for certifying computation with private models but has only been applied to unrealistically small models.In this work, we present the first framework, ZKML, to produce ZK-SNARKs for realistic ML models, including state-of-the-art vision models, a distilled GPT-2, and the ML model powering Twitter's recommendations. We accomplish this by designing an optimizing compiler from TensorFlow to circuits in the halo2 ZK-SNARK proving system. There are many equivalent ways to implement the same operations within ZK-SNARK circuits, and these design choices can affect performance by 24\texttimes{}. To efficiently compile ML models, ZKML contains two parts: gadgets (efficient constraints for low-level operations) and an optimizer to decide how to lay out the gadgets within a circuit. Combined, these optimizations enable proving on a wider range of models, faster proving, faster verification, and smaller proofs compared to prior work.},
booktitle = {Proceedings of the Nineteenth European Conference on Computer Systems},
pages = {560–574},
numpages = {15},
location = {Athens, Greece},
series = {EuroSys '24}
}

@misc{hyrax,
      author = {Riad S.  Wahby and Ioanna Tzialla and abhi shelat and Justin Thaler and Michael Walfish},
      title = {Doubly-efficient {zkSNARKs} without trusted setup},
      howpublished = {Cryptology {ePrint} Archive, Paper 2017/1132},
      year = {2017},
      url = {https://eprint.iacr.org/2017/1132}
}

@misc{nn-ezkl,
	title={Verifiable evaluations of machine learning models using zkSNARKs}, 
	author={Tobin South and Alexander Camuto and Shrey Jain and Shayla Nguyen and Robert Mahari and Christian Paquin and Jason Morton and Alex 'Sandy' Pentland},
	year={2024},
	eprint={2402.02675},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2402.02675}, 
}

@article{stark,
	title={Scalable, transparent, and post-quantum secure computational integrity},
	author={Eli Ben-Sasson and Iddo Bentov and Yinon Horesh and Michael Riabzev},
	journal={IACR Cryptol. ePrint Arch.},
	year={2018},
	volume={2018},
	pages={46},
	url={https://api.semanticscholar.org/CorpusID:44557939}
}


@inproceedings{bulletproofs,
	author = {Bunz, Benedikt and Bootle, Jonathan and Boneh, Dan and Poelstra, Andrew and Wuille, Pieter and Maxwell, Greg},
	doi = {10.1109/SP.2018.00020},
	month = {05},
	pages = {315-334},
	title = {Bulletproofs: Short Proofs for Confidential Transactions and More},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1109/SP.2018.00020}
}

@article{plonk,
  title={PLONK: Permutations over Lagrange-bases for Oecumenical Noninteractive arguments of Knowledge},
  author={Ariel Gabizon and Zachary J. Williamson and Oana-Madalina Ciobotaru},
  journal={IACR Cryptol. ePrint Arch.},
  year={2019},
  volume={2019},
  pages={953},
  url={https://api.semanticscholar.org/CorpusID:201685538}
}

@inproceedings{groth16,
    abstract = {Non-interactive arguments enable a prover to convince a verifier that a statement is true. Recently there has been a lot of progress both in theory and practice on constructing highly efficient non-interactive arguments with small size and low verification complexity, so-called succinct non-interactive arguments (SNARGs) and succinct non-interactive arguments of knowledge (SNARKs).},
    address = {Berlin, Heidelberg},
	author = {Groth, Jens},
	booktitle = {Advances in Cryptology -- EUROCRYPT 2016},
	editor = {Fischlin, Marc and Coron, Jean-S{\'e}bastien},
	isbn = {978-3-662-49896-5},
	pages = {305--326},
	publisher = {Springer Berlin Heidelberg},
	title = {On the Size of Pairing-Based Non-interactive Arguments},
	year = {2016}
}


@article{snark-survey,
	abstract = {In last years, there has been an increasing effort to leverage distributed ledger technology (DLT), including blockchain. One of the main topics of interest, given its importance, is the research and development of privacy mechanisms, as for example is the case of zero knowledge proofs (ZKP). ZKP is a cryptographic technique that can be used to hide information that is put into the ledger, while still allowing to perform validation of this data. In this work we describe different strategies to construct zero knowledge range proofs (ZKRP), as for example the scheme proposed by Boudot (in: Bart (ed) Advances in cryptology---EUROCRYPT 2000, Springer, Berlin, 2000) in 2001; the one proposed by Camenisch et al. (in: Josef (ed) Advances in cryptology---ASIACRYPT 2008, Springer, Berlin, 2008), and bulletproofs (B{\"u}nz et al., in: 2018 IEEE symposium on security and privacy (SP), 2018), proposed in 2017. We also compare these strategies and discuss possible use cases. Since bulletproofs (B{\"u}nz et al. 2018) is the most efficient construction, we will give a detailed description of its algorithms and optimizations. Bulletproofs is not only more efficient than previous schemes, but also avoids the trusted setup, which is a requirement that is not desirable in the context of DLT and blockchain. In case of cryptocurrencies, if the setup phase is compromised, it would be possible to generate money out of thin air. Interestingly, bulletproofs can also be used to construct generic ZKP, in the sense that it can be used to prove generic statements, and thus it is not only restricted to ZKRP, but it can be used for any kind of proof of knowledge. Hence Bulletproofs leads to a more powerful tool to provide privacy for DLT. Here we describe in detail the algorithms involved in Bulletproofs protocol for ZKRP. Also, we present our implementation, which was open sourced (Morais et al., in: Zero knowledge range proof implementation, 2018. https://github.com/ing-bank/zkrangeproof).},
	author = {Morais, Eduardo and Koens, Tommy and van Wijk, Cees and Koren, Aleksei},
	date = {2019/07/31},
	date-added = {2025-02-19 12:47:17 PM +0200},
	date-modified = {2025-02-19 12:47:17 PM +0200},
	doi = {10.1007/s42452-019-0989-z},
	id = {Morais2019},
	isbn = {2523-3971},
	journal = {SN Applied Sciences},
	number = {8},
	pages = {946},
	title = {A survey on zero knowledge range proofs and applications},
	url = {https://doi.org/10.1007/s42452-019-0989-z},
	volume = {1},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1007/s42452-019-0989-z}}

@inbook{lwe,
	author = {Zheng, Zhiyong and Tian, Kun and Liu, Fengxia},
	doi = {10.1007/978-981-19-7644-5_3},
	isbn = {978-981-19-7643-8},
	month = {12},
	pages = {53-98},
	title = {Learning with Error},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1007/978-981-19-7644-5_3}}

@misc{zksnark,
      author = {Junkai Liang and Daqi Hu and Pengfei Wu and Yunbo Yang and Qingni Shen and Zhonghai Wu},
      title = {{SoK}: Understanding zk-{SNARKs}: The Gap Between Research and Practice},
      howpublished = {Cryptology {ePrint} Archive, Paper 2025/172},
      year = {2025},
      url = {https://eprint.iacr.org/2025/172}
}

@ARTICLE{circom,
	author={Bellés-Muñoz, Marta and Isabel, Miguel and Muñoz-Tapia, Jose Luis and Rubio, Albert and Baylina, Jordi},
	journal={IEEE Transactions on Dependable and Secure Computing}, 
	title={Circom: A Circuit Description Language for Building Zero-Knowledge Applications}, 
	year={2023},
	volume={20},
	number={6},
	pages={4733-4751},
	keywords={Arithmetic;Wires;Logic gates;Smart contracts;Libraries;Distributed ledger;Program processors;Zero-knowledge proof;circuit;domain-specific language;compiler;blockchain},
	doi={10.1109/TDSC.2022.3232813}
}


@article{snark-stark-comparison,
	abstract = {Abstract This systematic literature review examines the implementation and analysis of zk-SNARK, zk-STARK, and bulletproof non-interactive zero-knowledge proof (NIZKP) protocols in privacy-preserving applications across diverse sectors. Examining 41 research works obtained through the systematic search queries and filtering criteria published from 2015 to April 2023, we categorized findings into financial, medical, business, general, and other domains. Our analysis highlights significant variations of up to several orders of magnitude in real-world performance across implementations utilizing NIZKP protocols. However, divergent methodologies in security analyses hindered conclusive comparisons. Addressing research gaps, our future endeavors aim to establish a real-world benchmark for these protocols.},
	author = {Oude Roelink, Bjorn and El-Hajj, Mohammed and Sarmah, Dipti},
	doi = {https://doi.org/10.1002/spy2.401},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/spy2.401},
	journal = {SECURITY AND PRIVACY},
	keywords = {bulletproof, performance, privacy-preserving, security analysis, zero knowledge, zk-SNARK, zk-STARK},
	number = {5},
	pages = {e401},
	title = {Systematic review: Comparing zk-SNARK, zk-STARK, and bulletproof protocols for privacy-preserving authentication},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spy2.401},
	volume = {7},
	year = {2024},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spy2.401},
	bdsk-url-2 = {https://doi.org/10.1002/spy2.401}
}


@inproceedings{pairings_r1cs,
	abstract = {Bilinear pairings have been used in different cryptographic applications and demonstrated to be a key building block for a plethora of constructions. In particular, some Succinct Non-interactive ARguments of Knowledge (SNARKs) have very short proofs and very fast verification thanks to a multi-pairing computation. This succinctness makes pairing-based SNARKs suitable for proof recursion, that is proofs verifying other proofs. In this scenario one requires to express efficiently a multi-pairing computation as a SNARK arithmetic circuit. Other compelling applications such as verifying Boneh--Lynn--Shacham (BLS) signatures or Kate--Zaverucha--Goldberg (KZG) polynomial commitment opening in a SNARK fall into the same requirement. The implementation of pairings is challenging but the literature has very detailed approaches on how to reach practical and optimized implementations in different contexts and for different target environments. However, to the best of our knowledge, no previous publication has addressed the question of efficiently implementing a pairing as a SNARK arithmetic circuit. In this work, we consider efficiently implementing pairings in Rank-1 Constraint Systems (R1CS), a widely used model to express SNARK statements. We show that our techniques almost halve the arithmetic circuit depth of the previously best known pairing implementation on a Barreto--Lynn--Scott (BLS) curve of embedding degree 12, resulting in 70{\%} faster proving time. We also investigate and implement the case of BLS curves of embedding degree 24.},
	address = {Cham},
	author = {Housni, Youssef El},
	booktitle = {Applied Cryptography and Network Security},
	editor = {Tibouchi, Mehdi and Wang, XiaoFeng},
	isbn = {978-3-031-33488-7},
	pages = {339--362},
	publisher = {Springer Nature Switzerland},
	title = {Pairings in Rank-1 Constraint Systems},
	year = {2023}
}


@inproceedings{posseidon,
	title={Poseidon: A New Hash Function for Zero-Knowledge Proof Systems},
	author={Lorenzo Grassi and Dmitry Khovratovich and Christian Rechberger and Arnab Roy and Markus Schofnegger},
	booktitle={USENIX Security Symposium},
	year={2021},
	url={https://api.semanticscholar.org/CorpusID:221069468}
}


@article{ec_r1cs,
	author = {Aranha, Diego F. and El Housni, Youssef and Guillevic, Aurore},
	title = {A survey of elliptic curves for proof systems},
	year = {2022},
	issue_date = {Nov 2023},
	publisher = {Kluwer Academic Publishers},
	address = {USA},
	volume = {91},
	number = {11},
	issn = {0925-1022},
	url = {https://doi.org/10.1007/s10623-022-01135-y},
	doi = {10.1007/s10623-022-01135-y},
	abstract = {Elliptic curves have become key ingredients for instantiating zero-knowledge proofs and more generally proof systems. Recently, there have been many tailored constructions of these curves that aim at efficiently implementing different kinds of proof systems. In this survey we provide the reader with a comprehensive overview on existing work and revisit the contributions in terms of efficiency and security. We present an overview at three stages of the process: curves to instantiate a SNARK, curves to instantiate a recursive SNARK, and also curves to express an elliptic-curve related statement. We provide new constructions of curves for SNARKs and generalize the state-of-the-art constructions for recursive SNARKs. We also exhaustively document the existing work and open-source implementations.},
	journal = {Des. Codes Cryptography},
	month = dec,
	pages = {3333–3378},
	numpages = {46},
	keywords = {Elliptic curves, Pairings, Proof systems, SNARKs, 11T71, 11Y16, 11-04, 11Y40}
}

@misc{zkml-genai,
      title={Trust the Process: Zero-Knowledge Machine Learning to Enhance Trust in Generative AI Interactions}, 
      author={Bianca-Mihaela Ganescu and Jonathan Passerat-Palmbach},
      year={2024},
      eprint={2402.06414},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.06414}, 
}

@misc{artemis,
      title={Artemis: Efficient Commit-and-Prove SNARKs for zkML}, 
      author={Hidde Lycklama and Alexander Viand and Nikolay Avramov and Nicolas Küchler and Anwar Hithnawi},
      year={2024},
      eprint={2409.12055},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2409.12055}, 
}

@inproceedings{ddkang-zkml,
author = {Chen, Bing-Jyue and Waiwitlikhit, Suppakit and Stoica, Ion and Kang, Daniel},
title = {ZKML: An Optimizing System for ML Inference in Zero-Knowledge Proofs},
year = {2024},
isbn = {9798400704376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627703.3650088},
doi = {10.1145/3627703.3650088},
abstract = {Machine learning (ML) is increasingly used behind closed systems and APIs to make important decisions. For example, social media uses ML-based recommendation algorithms to decide what to show users, and millions of people pay to use ChatGPT for information every day. Because ML is deployed behind these closed systems, there are increasing calls for transparency, such as releasing model weights. However, these service providers have legitimate reasons not to release this information, including for privacy and trade secrets. To bridge this gap, recent work has proposed using zero-knowledge proofs (specifically a form called ZK-SNARKs) for certifying computation with private models but has only been applied to unrealistically small models.In this work, we present the first framework, ZKML, to produce ZK-SNARKs for realistic ML models, including state-of-the-art vision models, a distilled GPT-2, and the ML model powering Twitter's recommendations. We accomplish this by designing an optimizing compiler from TensorFlow to circuits in the halo2 ZK-SNARK proving system. There are many equivalent ways to implement the same operations within ZK-SNARK circuits, and these design choices can affect performance by 24\texttimes{}. To efficiently compile ML models, ZKML contains two parts: gadgets (efficient constraints for low-level operations) and an optimizer to decide how to lay out the gadgets within a circuit. Combined, these optimizations enable proving on a wider range of models, faster proving, faster verification, and smaller proofs compared to prior work.},
booktitle = {Proceedings of the Nineteenth European Conference on Computer Systems},
pages = {560–574},
numpages = {15},
location = {Athens, Greece},
series = {EuroSys '24}
}

@misc{ezkl,
      title={Verifiable evaluations of machine learning models using zkSNARKs}, 
      author={Tobin South and Alexander Camuto and Shrey Jain and Shayla Nguyen and Robert Mahari and Christian Paquin and Jason Morton and Alex 'Sandy' Pentland},
      year={2024},
      eprint={2402.02675},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.02675}, 
}

@article{mobilenetv2,
  title={MobileNetV2: Inverted Residuals and Linear Bottlenecks},
  author={Mark Sandler and Andrew G. Howard and Menglong Zhu and Andrey Zhmoginov and Liang-Chieh Chen},
  journal={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2018},
  pages={4510-4520},
  url={https://api.semanticscholar.org/CorpusID:4555207}
}

@misc{taprootized-swaps,
      title={Multichain Taprootized Atomic Swaps: Introducing Untraceability through Zero-Knowledge Proofs}, 
      author={Oleksandr Kurbatov and Dmytro Zakharov and Anton Levochko and Kyrylo Riabov and Bohdan Skriabin},
      year={2024},
      eprint={2402.16735},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2402.16735}, 
}


@inbook{schnorr-identification,
	address = {Boston, MA},
	author = {Just, Mike},
	booktitle = {Encyclopedia of Cryptography and Security},
	doi = {10.1007/978-1-4419-5906-5_95},
	editor = {van Tilborg, Henk C. A. and Jajodia, Sushil},
	isbn = {978-1-4419-5906-5},
	pages = {1083--1083},
	publisher = {Springer US},
	title = {Schnorr Identification Protocol},
	url = {https://doi.org/10.1007/978-1-4419-5906-5_95},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.1007/978-1-4419-5906-5_95}}

@inproceedings{okamoto-identification,
author = {Krzywiecki, Lukasz and Kutylowski, Miroslaw},
title = {Security of Okamoto Identification Scheme: a Defense against Ephemeral Key Leakage and Setup},
year = {2017},
isbn = {9781450349703},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3055259.3055267},
doi = {10.1145/3055259.3055267},
abstract = {We consider the situation, where an adversary may learn the ephemeral values used by the prover within an identification protocol, aiming to get the secret keys of the user, or just to impersonate the prover subsequently. Unfortunately, most classical cryptographic identification protocols are exposed to such attacks, which might be quite realistic in case of software implementations. According to a recent proposal from SECIT-2017, we regard a scheme to be secure, if a malicious verifier, allowed to set the prover's ephemerals in the query stage, cannot impersonate the prover later on. We focus on the Okamoto Identification Scheme (IS), and show how to make it immune to the threats described above. Via reduction to the GDH Problem, we provide security guarantees in case of insufficient control over the unit executing Okamoto identification protocol (the standard Okamoto protocol is insecure in this situation).},
booktitle = {Proceedings of the Fifth ACM International Workshop on Security in Cloud Computing},
pages = {43–50},
numpages = {8},
keywords = {simulatability, security reduction, provable security, leakage, impersonation, identification, ephemeral random values, Okamoto scheme, GDH},
location = {Abu Dhabi, United Arab Emirates},
series = {SCC '17}
}

@article{adam,
  title={Adam: A Method for Stochastic Optimization},
  author={Diederik P. Kingma and Jimmy Ba},
  journal={CoRR},
  year={2014},
  volume={abs/1412.6980},
  url={https://api.semanticscholar.org/CorpusID:6628106}
}

@misc{sgd,
      title={An overview of gradient descent optimization algorithms}, 
      author={Sebastian Ruder},
      year={2017},
      eprint={1609.04747},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1609.04747}, 
}

@article{inverting_1,
  title={Inverting face embeddings with convolutional neural networks},
  author={Andrey Zhmoginov and Mark Sandler},
  journal={ArXiv},
  year={2016},
  volume={abs/1606.04189},
  url={https://api.semanticscholar.org/CorpusID:15785666}
}


@inproceedings{inverting_2,
	author = {Roig, Daile and Gerlitz, Paul-Anton and Rathgeb, Christian and Busch, Christoph},
	doi = {10.1109/WIFS58808.2023.10374819},
	month = {12},
	pages = {1-6},
	title = {Reversing Deep Face Embeddings with Probable Privacy Protection},
	year = {2023},
	bdsk-url-1 = {https://doi.org/10.1109/WIFS58808.2023.10374819}}


@INPROCEEDINGS{eigenface,
  author={Turk, M.A. and Pentland, A.P.},
  booktitle={Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition}, 
  title={Face recognition using eigenfaces}, 
  year={1991},
  volume={},
  number={},
  pages={586-591},
  keywords={Face recognition;Face detection;Humans;Character recognition;Computer vision;Head;Eyes;Nose;Computational modeling;Image recognition},
  doi={10.1109/CVPR.1991.139758}}

@ARTICLE{fisherface,
  author={Belhumeur, P.N. and Hespanha, J.P. and Kriegman, D.J.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Eigenfaces vs. Fisherfaces: recognition using class specific linear projection}, 
  year={1997},
  volume={19},
  number={7},
  pages={711-720},
  keywords={Face recognition;Light scattering;Lighting;Face detection;Principal component analysis;Shadow mapping;Light sources;Pattern classification;Pixel;Error analysis},
  doi={10.1109/34.598228}}


@inproceedings{facenet,
   title={FaceNet: A unified embedding for face recognition and clustering},
   url={http://dx.doi.org/10.1109/CVPR.2015.7298682},
   DOI={10.1109/cvpr.2015.7298682},
   booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
   publisher={IEEE},
   author={Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
   year={2015},
   month=jun, pages={815–823} }

@ARTICLE{cnn,
  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324},
  keywords={Neural networks;Pattern recognition;Machine learning;Optical character recognition software;Character recognition;Feature extraction;Multi-layer neural network;Optical computing;Hidden Markov models;Principal component analysis},
  doi={10.1109/5.726791}}

@inproceedings{cifar-10,
  title={Learning Multiple Layers of Features from Tiny Images},
  author={Alex Krizhevsky},
  year={2009},
  url={https://api.semanticscholar.org/CorpusID:18268744}
}

@misc{fashion-mnist,
      title={Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms}, 
      author={Han Xiao and Kashif Rasul and Roland Vollgraf},
      year={2017},
      eprint={1708.07747},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1708.07747}, 
}

@misc{tf,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro et al.},
  year={2015},
}

@misc{se-network,
      title={Squeeze-and-Excitation Networks}, 
      author={Jie Hu and Li Shen and Samuel Albanie and Gang Sun and Enhua Wu},
      year={2019},
      eprint={1709.01507},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1709.01507}, 
}